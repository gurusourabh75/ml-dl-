{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world \n"
     ]
    }
   ],
   "source": [
    "print('hello world ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas = adds data structure and toold designed to work with table like dtara ( similar to series )\n",
    "- allow to handel missing data \n",
    "- provide tools like reshaping , merging sorting slicing and indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numpy =  should work on arithmatic operation& array operation\n",
    "- pandas = data manipulation = data frame = 3d  and series = 2d \n",
    "- scikit = used for mechie learning operaton\n",
    "- keras = used for deep learing operation/ tensor flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIZUALTION LIBARIES \n",
    "\n",
    "- matpolotlib = is for basic vizualization\n",
    "- seaborn = for advance vizulation \n",
    "- ploty = is very rarely use depends on numpy and pandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gurusourabh/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>discipline</th>\n",
       "      <th>phd</th>\n",
       "      <th>service</th>\n",
       "      <th>sex</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>186960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>110515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>131205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>81285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>94350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>57800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank discipline  phd  service   sex  salary\n",
       "0       Prof          B   56       49  Male  186960\n",
       "1       Prof          A   12        6  Male   93000\n",
       "2       Prof          A   23       20  Male  110515\n",
       "3       Prof          A   40       31  Male  131205\n",
       "4       Prof          B   20       18  Male  104800\n",
       "5       Prof          A   20       20  Male  122400\n",
       "6  AssocProf          A   20       17  Male   81285\n",
       "7       Prof          A   18       18  Male  126300\n",
       "8       Prof          A   29       19  Male   94350\n",
       "9       Prof          A   51       51  Male   57800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Salaries.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78 entries, 0 to 77\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rank        78 non-null     object\n",
      " 1   discipline  78 non-null     object\n",
      " 2   phd         78 non-null     int64 \n",
      " 3   service     78 non-null     int64 \n",
      " 4   sex         78 non-null     object\n",
      " 5   salary      78 non-null     int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols: 'UsecolsArgType' = None, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters: 'Mapping[Hashable, Callable] | None' = None, true_values: 'list | None' = None, false_values: 'list | None' = None, skipinitialspace: 'bool' = False, skiprows: 'list[int] | int | Callable[[Hashable], bool] | None' = None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values: 'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None' = None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool | lib.NoDefault' = <no_default>, skip_blank_lines: 'bool' = True, parse_dates: 'bool | Sequence[Hashable] | None' = None, infer_datetime_format: 'bool | lib.NoDefault' = <no_default>, keep_date_col: 'bool | lib.NoDefault' = <no_default>, date_parser: 'Callable | lib.NoDefault' = <no_default>, date_format: 'str | dict[Hashable, str] | None' = None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, on_bad_lines: 'str' = 'error', delim_whitespace: 'bool | lib.NoDefault' = <no_default>, low_memory: 'bool' = True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions | None' = None, dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "\n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "        C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator from only the first valid\n",
      "        row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "        In addition, separators longer than 1 character and different from\n",
      "        ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "        the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "        to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, optional\n",
      "        Alias for ``sep``.\n",
      "    header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "        Row number(s) containing column labels and marking the start of the\n",
      "        data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly to ``names`` then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "        e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : Sequence of Hashable, optional\n",
      "        Sequence of column labels to apply. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : Hashable, Sequence of Hashable or False, optional\n",
      "      Column(s) to use as row label(s), denoted either by column labels or column\n",
      "      indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
      "      will be formed for the row labels.\n",
      "\n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g., when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : Sequence of Hashable or Callable, optional\n",
      "        Subset of columns to select, denoted either by column labels or column indices.\n",
      "        If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in ``names`` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "        preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "        for columns in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "\n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to ``True``. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    dtype : dtype or dict of {Hashable : dtype}, optional\n",
      "        Data type(s) to apply to either the whole dataset or individual columns.\n",
      "        E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
      "        Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "        to preserve and not interpret ``dtype``.\n",
      "        If ``converters`` are specified, they will be applied INSTEAD\n",
      "        of ``dtype`` conversion.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "\n",
      "            Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
      "            the default determines the ``dtype`` of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "\n",
      "        .. versionadded:: 1.4.0\n",
      "\n",
      "            The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict of {Hashable : Callable}, optional\n",
      "        Functions for converting values in specified columns. Keys can either\n",
      "        be column labels or column indices.\n",
      "    true_values : list, optional\n",
      "        Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
      "    false_values : list, optional\n",
      "        Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : int, list of int or Callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "        at the start of the file.\n",
      "\n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
      "        Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
      "        per-column ``NA`` values.  By default the following values are interpreted as\n",
      "        ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
      "        \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
      "        \"n/a\", \"nan\", \"null \".\n",
      "\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "        Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "\n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
      "          is appended to the default ``NaN`` values used for parsing.\n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "          the default ``NaN`` values are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "          the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "          strings will be parsed as ``NaN``.\n",
      "\n",
      "        Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
      "        ``na_values`` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "        data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "        performance of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of ``NA`` values placed in non-numeric columns.\n",
      "\n",
      "        .. deprecated:: 2.2.0\n",
      "    skip_blank_lines : bool, default True\n",
      "        If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "    parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
      "        The behavior is as follows:\n",
      "\n",
      "        * ``bool``. If ``True`` -> try parsing the index. Note: Automatically set to\n",
      "          ``True`` if ``date_format`` or ``date_parser`` arguments have been passed.\n",
      "        * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
      "          as a single date column. Values are joined with a space before parsing.\n",
      "        * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
      "          result 'foo'. Values are joined with a space before parsing.\n",
      "\n",
      "        If a column or index cannot be represented as an array of ``datetime``,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an ``object`` data type. For\n",
      "        non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "        :func:`~pandas.read_csv`.\n",
      "\n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
      "        format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "\n",
      "        .. deprecated:: 2.0.0\n",
      "            A strict version of this argument is now the default, passing it has no effect.\n",
      "\n",
      "    keep_date_col : bool, default False\n",
      "        If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : Callable, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. pandas will try to call ``date_parser`` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by ``parse_dates`` into a single array\n",
      "        and pass that; and 3) call ``date_parser`` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by ``parse_dates``) as\n",
      "        arguments.\n",
      "\n",
      "        .. deprecated:: 2.0.0\n",
      "           Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "           :func:`~pandas.to_datetime` as-needed.\n",
      "    date_format : str or dict of column -> format, optional\n",
      "        Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
      "        The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "        `strftime documentation\n",
      "        <https://docs.python.org/3/library/datetime.html\n",
      "        #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "        note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "        You can also pass:\n",
      "\n",
      "        - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "            time string (not necessarily in exactly the same format);\n",
      "        - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "            and you should probably use it along with `dayfirst`.\n",
      "\n",
      "        .. versionadded:: 2.0.0\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "\n",
      "    iterator : bool, default False\n",
      "        Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, optional\n",
      "        Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "        function to return a ``TextFileReader`` object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "        other key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "            Added support for `.tar` files.\n",
      "\n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "    thousands : str (length 1), optional\n",
      "        Character acting as the thousands separator in numerical values.\n",
      "    decimal : str (length 1), default '.'\n",
      "        Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character used to denote a line break. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        Character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the ``delimiter`` and it will be ignored.\n",
      "    quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "        ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
      "        characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
      "        or ``lineterminator``.\n",
      "    doublequote : bool, default True\n",
      "       When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        Character used to escape other characters.\n",
      "    comment : str (length 1), optional\n",
      "        Character indicating that the remainder of line should not be parsed.\n",
      "        If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter ``header`` but not by\n",
      "        ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "        treated as the header.\n",
      "    encoding : str, optional, default 'utf-8'\n",
      "        Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "    encoding_errors : str, optional, default 'strict'\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "        .. versionadded:: 1.3.0\n",
      "\n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "        ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "        override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "        documentation for more details.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "\n",
      "        - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "        - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
      "        - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
      "\n",
      "        .. versionadded:: 1.3.0\n",
      "\n",
      "        .. versionadded:: 1.4.0\n",
      "\n",
      "            - Callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new ``list`` of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine='python'``\n",
      "\n",
      "        .. versionchanged:: 2.2.0\n",
      "\n",
      "            - Callable, function with signature\n",
      "              as described in `pyarrow documentation\n",
      "              <https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html\n",
      "              #pyarrow.csv.ParseOptions.invalid_row_handler>`_ when ``engine='pyarrow'``\n",
      "\n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "        used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to ``True``, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "\n",
      "        .. deprecated:: 2.2.0\n",
      "            Use ``sep=\"\\s+\"`` instead.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "        Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "        regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
      "        chunks. (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "        ``'legacy'`` for the original lower precision pandas converter, and\n",
      "        ``'round_trip'`` for the round-trip converter.\n",
      "\n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "    dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "        Back-end data type applied to the resultant :class:`DataFrame`\n",
      "        (still experimental). Behaviour is as follows:\n",
      "\n",
      "        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "          (default).\n",
      "        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "          DataFrame.\n",
      "\n",
      "        .. versionadded:: 2.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextFileReader\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_table : Read general delimited file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 6)\n"
     ]
    }
   ],
   "source": [
    "df.head(10)# frist 10 observaitons\n",
    "df.tail(10)# lats 10 observations\n",
    "print(df.shape) # tell us no of rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rank', 'discipline', 'phd', 'service', 'sex', 'salary'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # tell us no of coloums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank          object\n",
       "discipline    object\n",
       "phd            int64\n",
       "service        int64\n",
       "sex           object\n",
       "salary         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # tell us data types of each coloum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tell us data types of each coloum \n",
    "- from above object  means  any categorical data refer as object or others are number so int64 or float64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     186960\n",
       "1      93000\n",
       "2     110515\n",
       "3     131205\n",
       "4     104800\n",
       "       ...  \n",
       "73    105450\n",
       "74    104542\n",
       "75    124312\n",
       "76    109954\n",
       "77    109646\n",
       "Name: salary, Length: 78, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to accuss to a perticular coloum \n",
    "df['salary'] # here u can use both single court or double count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rank\"].dtype # to access to ranks coloum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78 entries, 0 to 77\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rank        78 non-null     object\n",
      " 1   discipline  78 non-null     object\n",
      " 2   phd         78 non-null     int64 \n",
      " 3   service     78 non-null     int64 \n",
      " 4   sex         78 non-null     object\n",
      " 5   salary      78 non-null     int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- suppose in rsnt we get 75 non null means 2 null valaues are there from above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RangeIndex(start=0, stop=78, step=1),\n",
       " Index(['rank', 'discipline', 'phd', 'service', 'sex', 'salary'], dtype='object')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Prof', 'B', 56, 49, 'Male', 186960],\n",
       "       ['Prof', 'A', 12, 6, 'Male', 93000],\n",
       "       ['Prof', 'A', 23, 20, 'Male', 110515],\n",
       "       ['Prof', 'A', 40, 31, 'Male', 131205],\n",
       "       ['Prof', 'B', 20, 18, 'Male', 104800],\n",
       "       ['Prof', 'A', 20, 20, 'Male', 122400],\n",
       "       ['AssocProf', 'A', 20, 17, 'Male', 81285],\n",
       "       ['Prof', 'A', 18, 18, 'Male', 126300],\n",
       "       ['Prof', 'A', 29, 19, 'Male', 94350],\n",
       "       ['Prof', 'A', 51, 51, 'Male', 57800],\n",
       "       ['Prof', 'B', 39, 33, 'Male', 128250],\n",
       "       ['Prof', 'B', 23, 23, 'Male', 134778],\n",
       "       ['AsstProf', 'B', 1, 0, 'Male', 88000],\n",
       "       ['Prof', 'B', 35, 33, 'Male', 162200],\n",
       "       ['Prof', 'B', 25, 19, 'Male', 153750],\n",
       "       ['Prof', 'B', 17, 3, 'Male', 150480],\n",
       "       ['AsstProf', 'B', 8, 3, 'Male', 75044],\n",
       "       ['AsstProf', 'B', 4, 0, 'Male', 92000],\n",
       "       ['Prof', 'A', 19, 7, 'Male', 107300],\n",
       "       ['Prof', 'A', 29, 27, 'Male', 150500],\n",
       "       ['AsstProf', 'B', 4, 4, 'Male', 92000],\n",
       "       ['Prof', 'A', 33, 30, 'Male', 103106],\n",
       "       ['AsstProf', 'A', 4, 2, 'Male', 73000],\n",
       "       ['AsstProf', 'A', 2, 0, 'Male', 85000],\n",
       "       ['Prof', 'A', 30, 23, 'Male', 91100],\n",
       "       ['Prof', 'B', 35, 31, 'Male', 99418],\n",
       "       ['Prof', 'A', 38, 19, 'Male', 148750],\n",
       "       ['Prof', 'A', 45, 43, 'Male', 155865],\n",
       "       ['AsstProf', 'B', 7, 2, 'Male', 91300],\n",
       "       ['Prof', 'B', 21, 20, 'Male', 123683],\n",
       "       ['AssocProf', 'B', 9, 7, 'Male', 107008],\n",
       "       ['Prof', 'B', 22, 21, 'Male', 155750],\n",
       "       ['Prof', 'A', 27, 19, 'Male', 103275],\n",
       "       ['Prof', 'B', 18, 18, 'Male', 120000],\n",
       "       ['AssocProf', 'B', 12, 8, 'Male', 119800],\n",
       "       ['Prof', 'B', 28, 23, 'Male', 126933],\n",
       "       ['Prof', 'B', 45, 45, 'Male', 146856],\n",
       "       ['Prof', 'A', 20, 8, 'Male', 102000],\n",
       "       ['AsstProf', 'B', 4, 3, 'Male', 91000],\n",
       "       ['Prof', 'B', 18, 18, 'Female', 129000],\n",
       "       ['Prof', 'A', 39, 36, 'Female', 137000],\n",
       "       ['AssocProf', 'A', 13, 8, 'Female', 74830],\n",
       "       ['AsstProf', 'B', 4, 2, 'Female', 80225],\n",
       "       ['AsstProf', 'B', 5, 0, 'Female', 77000],\n",
       "       ['Prof', 'B', 23, 19, 'Female', 151768],\n",
       "       ['Prof', 'B', 25, 25, 'Female', 140096],\n",
       "       ['AsstProf', 'B', 11, 3, 'Female', 74692],\n",
       "       ['AssocProf', 'B', 11, 11, 'Female', 103613],\n",
       "       ['Prof', 'B', 17, 17, 'Female', 111512],\n",
       "       ['Prof', 'B', 17, 18, 'Female', 122960],\n",
       "       ['AsstProf', 'B', 10, 5, 'Female', 97032],\n",
       "       ['Prof', 'B', 20, 14, 'Female', 127512],\n",
       "       ['Prof', 'A', 12, 0, 'Female', 105000],\n",
       "       ['AsstProf', 'A', 5, 3, 'Female', 73500],\n",
       "       ['AssocProf', 'A', 25, 22, 'Female', 62884],\n",
       "       ['AsstProf', 'A', 2, 0, 'Female', 72500],\n",
       "       ['AssocProf', 'A', 10, 8, 'Female', 77500],\n",
       "       ['AsstProf', 'A', 3, 1, 'Female', 72500],\n",
       "       ['Prof', 'B', 36, 26, 'Female', 144651],\n",
       "       ['AssocProf', 'B', 12, 10, 'Female', 103994],\n",
       "       ['AsstProf', 'B', 3, 3, 'Female', 92000],\n",
       "       ['AssocProf', 'B', 13, 10, 'Female', 103750],\n",
       "       ['AssocProf', 'B', 14, 7, 'Female', 109650],\n",
       "       ['Prof', 'A', 29, 27, 'Female', 91000],\n",
       "       ['AssocProf', 'A', 26, 24, 'Female', 73300],\n",
       "       ['Prof', 'A', 36, 19, 'Female', 117555],\n",
       "       ['AsstProf', 'A', 7, 6, 'Female', 63100],\n",
       "       ['Prof', 'A', 17, 11, 'Female', 90450],\n",
       "       ['AsstProf', 'A', 4, 2, 'Female', 77500],\n",
       "       ['Prof', 'A', 28, 7, 'Female', 116450],\n",
       "       ['AsstProf', 'A', 8, 3, 'Female', 78500],\n",
       "       ['AssocProf', 'B', 12, 9, 'Female', 71065],\n",
       "       ['Prof', 'B', 24, 15, 'Female', 161101],\n",
       "       ['Prof', 'B', 18, 10, 'Female', 105450],\n",
       "       ['AssocProf', 'B', 19, 6, 'Female', 104542],\n",
       "       ['Prof', 'B', 17, 17, 'Female', 124312],\n",
       "       ['Prof', 'A', 28, 14, 'Female', 109954],\n",
       "       ['Prof', 'A', 23, 15, 'Female', 109646]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DATA TYPES\n",
    "\n",
    "\n",
    "- 1 OBJECT = STRING = categorical data\n",
    "- 2 int64 = integer data = numbers where 64 is the number allocated to the memory \n",
    "- 3 flot = decimal data = numbers where it have decimal values like 2.4,3.5 etc \n",
    "- 4 datatime64  = data and time in python standard library = look into these time series and expermemnt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DATA FRAME AND ATTRIBUTES \n",
    "\n",
    "\n",
    "- dtype   = list the type of coloumns\n",
    "- coloums =list the coloumns names \n",
    "- axes    = list the row lables and coloumns names \n",
    "- ndim    = number of demensions \n",
    "- size    = number of elementss\n",
    "- shape   = number of rows and coloumns \n",
    "- values  = numpy representation of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if we look in shape the out put is (78,6) if u see the data in mormal parentesis is called tuple if u see the data in square brackets is called list\n",
    "- wher tuple are immutable and list are mutable ,mutable means we can change the data in the list but in tuple we cannot change the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE \n",
    "\n",
    "- find how many records this data frames has        = df.shape[]\n",
    "- how many coloumns are there                       = df.shape[]\n",
    "- what are the colooumns names                     = df.coloumns\n",
    "- what type of coloumns we have in thid data frame =df.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA FRAME METHODS \n",
    "\n",
    "\n",
    "- head(n),tail(n)     = top no of rows ,last no of rows \n",
    "- descride()          = it generate descriptive statistics for only numerical coloums  here descriptive statistics means mean median and mode ,standaead deviation etc \n",
    "- max(),min()         = it gives the max and min values of each coloumns for numeriacial data \n",
    "- mean(), median()   = to find the mean and median of each coloumns \n",
    "- std()               = to find the standard deviation of each coloumns \n",
    "- sample(n)           = to find the sample of n rows \n",
    "- dropna()            = to drop the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phd</th>\n",
       "      <th>service</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.705128</td>\n",
       "      <td>15.051282</td>\n",
       "      <td>108023.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.498425</td>\n",
       "      <td>12.139768</td>\n",
       "      <td>28293.661022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.250000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>88612.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>104671.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.750000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>126774.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>186960.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             phd    service         salary\n",
       "count  78.000000  78.000000      78.000000\n",
       "mean   19.705128  15.051282  108023.782051\n",
       "std    12.498425  12.139768   28293.661022\n",
       "min     1.000000   0.000000   57800.000000\n",
       "25%    10.250000   5.250000   88612.500000\n",
       "50%    18.500000  14.500000  104671.000000\n",
       "75%    27.750000  20.750000  126774.750000\n",
       "max    56.000000  51.000000  186960.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here 50% is the median value\n",
    "- min and max without removing the outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank          object\n",
      "discipline    object\n",
      "phd            int64\n",
      "service        int64\n",
      "sex           object\n",
      "salary         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the DataFrame columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phd        0.634366\n",
      "service    0.913750\n",
      "salary     0.452103\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df=df.select_dtypes(include=[np.number])\n",
    "# Calculate skewness for numeric columns\n",
    "skewness=numeric_df.skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " df.skew() is a method used to compute the skewness of the distribution of each column in a DataFrame\n",
    "\n",
    " A skewness value of 0 indicates a perfectly symmetrical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Rules for Interpreting Skewness:\n",
    "\n",
    "1. Skewness ≈ 0: The distribution is nearly symmetric.\n",
    "\n",
    "2.Positive Skewness (> 0): The distribution has a long tail on the right (most values are concentrated on the left).\n",
    "\n",
    "3.Negative Skewness (< 0): The distribution has a long tail on the left (most values are concentrated on the right).\n",
    "\n",
    "4.Magnitude:\n",
    "- Small Skewness (< 0.5): Distribution is approximately symmetric.\n",
    "- Moderate Skewness (0.5 to 1): Distribution is moderately skewed.\n",
    "- High Skewness (> 1): Distribution is highly skewed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --------------------- OR --------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Column A (0.634366): This value is positive but close to 0. This means the distribution of the values in Column A is slightly right-skewed, but not extremely so. There is a mild tail on the right side, but it’s not very pronounced.\n",
    "\n",
    "Column B (0.913750): This value is positive and a bit larger than Column A. It suggests that the values in Column B have a moderate right skew—there is still a tail to the right, but not a very extreme one.\n",
    "\n",
    "Column C (0.452103): This value is positive but closer to 0 again. Similar to Column A, it suggests that Column C is slightly right-skewed.\n",
    "\n",
    "How to interpret positive skewness values:\n",
    "Near 0 (like 0.634366 or 0.452103): The distribution is nearly symmetric, but with a slight tail on the right side.\n",
    "Above 1: A stronger right-skew, meaning the right tail is more noticeable.\n",
    "Negative values: Would indicate left-skewness (tail on the left side)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank          object\n",
      "discipline    object\n",
      "phd            int64\n",
      "service        int64\n",
      "sex           object\n",
      "salary         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phd        0.042504\n",
      "service    0.608981\n",
      "salary    -0.401713\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kurtosis= numeric_df.kurt()\n",
    "print(kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here what we did is for we already seperated numerical coloumns into numeric_df in previous skew now we use the same numeric_df for kurt so \"\"\"kurtosis= numeric_df.kurt()\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phd            19.705128\n",
       "service        15.051282\n",
       "salary     108023.782051\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phd</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.705128</td>\n",
       "      <td>15.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.498425</td>\n",
       "      <td>12.139768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.250000</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>14.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.750000</td>\n",
       "      <td>20.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             phd    service\n",
       "count  78.000000  78.000000\n",
       "mean   19.705128  15.051282\n",
       "std    12.498425  12.139768\n",
       "min     1.000000   0.000000\n",
       "25%    10.250000   5.250000\n",
       "50%    18.500000  14.500000\n",
       "75%    27.750000  20.750000\n",
       "max    56.000000  51.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"phd\",\"service\"]].describe() # we used double bracket because we are using two coloumns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "Male      39\n",
       "Female    39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     56\n",
       "1     12\n",
       "2     23\n",
       "3     40\n",
       "4     20\n",
       "      ..\n",
       "73    18\n",
       "74    19\n",
       "75    17\n",
       "76    28\n",
       "77    23\n",
       "Name: phd, Length: 78, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['phd'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank\n",
       "Prof         46\n",
       "AsstProf     19\n",
       "AssocProf    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank            Prof\n",
       "discipline         B\n",
       "phd               56\n",
       "service           51\n",
       "sex             Male\n",
       "salary        186960\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank          AssocProf\n",
       "discipline            A\n",
       "phd                   1\n",
       "service               0\n",
       "sex              Female\n",
       "salary            57800\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>discipline</th>\n",
       "      <th>phd</th>\n",
       "      <th>service</th>\n",
       "      <th>sex</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>77000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>75044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>148750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>78500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>153750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>151768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>74692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>Female</td>\n",
       "      <td>127512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>110515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>103613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>B</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>104542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>117555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>72500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>103275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>123683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>107008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>155865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Female</td>\n",
       "      <td>103994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>128250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>Female</td>\n",
       "      <td>109954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>126933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>131205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>73500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>146856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>90450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>122960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>57800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>99418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>144651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>186960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>81285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>103106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>Female</td>\n",
       "      <td>71065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>80225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AssocProf</td>\n",
       "      <td>B</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Female</td>\n",
       "      <td>103750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>109646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>94350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AsstProf</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rank discipline  phd  service     sex  salary\n",
       "40       Prof          A   39       36  Female  137000\n",
       "43   AsstProf          B    5        0  Female   77000\n",
       "16   AsstProf          B    8        3    Male   75044\n",
       "26       Prof          A   38       19    Male  148750\n",
       "70   AsstProf          A    8        3  Female   78500\n",
       "17   AsstProf          B    4        0    Male   92000\n",
       "14       Prof          B   25       19    Male  153750\n",
       "44       Prof          B   23       19  Female  151768\n",
       "46   AsstProf          B   11        3  Female   74692\n",
       "51       Prof          B   20       14  Female  127512\n",
       "2        Prof          A   23       20    Male  110515\n",
       "47  AssocProf          B   11       11  Female  103613\n",
       "74  AssocProf          B   19        6  Female  104542\n",
       "65       Prof          A   36       19  Female  117555\n",
       "57   AsstProf          A    3        1  Female   72500\n",
       "38   AsstProf          B    4        3    Male   91000\n",
       "32       Prof          A   27       19    Male  103275\n",
       "37       Prof          A   20        8    Male  102000\n",
       "29       Prof          B   21       20    Male  123683\n",
       "30  AssocProf          B    9        7    Male  107008\n",
       "27       Prof          A   45       43    Male  155865\n",
       "18       Prof          A   19        7    Male  107300\n",
       "59  AssocProf          B   12       10  Female  103994\n",
       "10       Prof          B   39       33    Male  128250\n",
       "76       Prof          A   28       14  Female  109954\n",
       "35       Prof          B   28       23    Male  126933\n",
       "3        Prof          A   40       31    Male  131205\n",
       "63       Prof          A   29       27  Female   91000\n",
       "53   AsstProf          A    5        3  Female   73500\n",
       "36       Prof          B   45       45    Male  146856\n",
       "67       Prof          A   17       11  Female   90450\n",
       "49       Prof          B   17       18  Female  122960\n",
       "9        Prof          A   51       51    Male   57800\n",
       "19       Prof          A   29       27    Male  150500\n",
       "25       Prof          B   35       31    Male   99418\n",
       "58       Prof          B   36       26  Female  144651\n",
       "0        Prof          B   56       49    Male  186960\n",
       "20   AsstProf          B    4        4    Male   92000\n",
       "6   AssocProf          A   20       17    Male   81285\n",
       "52       Prof          A   12        0  Female  105000\n",
       "22   AsstProf          A    4        2    Male   73000\n",
       "4        Prof          B   20       18    Male  104800\n",
       "21       Prof          A   33       30    Male  103106\n",
       "71  AssocProf          B   12        9  Female   71065\n",
       "42   AsstProf          B    4        2  Female   80225\n",
       "7        Prof          A   18       18    Male  126300\n",
       "61  AssocProf          B   13       10  Female  103750\n",
       "77       Prof          A   23       15  Female  109646\n",
       "8        Prof          A   29       19    Male   94350\n",
       "23   AsstProf          A    2        0    Male   85000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50=df.sample(50) # here we stored 50 random samples in df_50\n",
    "df_50# print the 50 saples \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(108176.6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50.salary.mean() # mean of salary of 50  samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df_50.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phd            21.58\n",
       "service        16.46\n",
       "salary     108176.60\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(108023.78205128205)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.salary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     186960\n",
       "1      93000\n",
       "2     110515\n",
       "3     131205\n",
       "4     104800\n",
       "       ...  \n",
       "73    105450\n",
       "74    104542\n",
       "75    124312\n",
       "76    109954\n",
       "77    109646\n",
       "Name: salary, Length: 78, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phd           13.840329\n",
       "service       13.427371\n",
       "salary     27744.172151\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(156.21062271062272)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phd.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(191.55469387755102)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50.phd.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(191.55469387755102)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.phd.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to calculate to population varace in python we have to go with numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(154.20792241946089)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(df.phd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECTING A COLOUMN IN A DATA SET \n",
    "\n",
    "\n",
    "- method 1 : subset the data frame using coloumn name : df['rank ]\n",
    "\n",
    "- metjod 2 : using coloumn name as an attribute : df.rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLES \n",
    "\n",
    "- calulate the basic statistics for phb coloumn :df.phd.describe ()\n",
    "- find how many values in the phd coloums (use count method ): df.phb.count()\n",
    "- calculate the average of phb : df.phb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME GROUPBY METHOD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUPBY \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- splecting data into groups based on sertain criteria \n",
    "- calculate stats or apple function to each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>101002.410256</td>\n",
       "      <td>11.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>115045.153846</td>\n",
       "      <td>18.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               salary    service\n",
       "sex                             \n",
       "Female  101002.410256  11.564103\n",
       "Male    115045.153846  18.538462"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['sex'])[[\"salary\",\"service\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (1061131450.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[73], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    df.groupby9(['rank',sort=False])[[\"salary\",\"service\"]].mean()\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "df.groupby9(['rank',sort=False])[[\"salary\",\"service\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
